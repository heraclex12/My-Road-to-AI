{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AIHackathon: NoisyEffecientNetB7 weighted",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/heraclex12/My-Road-to-AI/blob/master/AIHackathon_NoisyEffecientNetB7_weighted.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9f7RddE1aVa5"
      },
      "source": [
        "## Setup and Prepare data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RR9yUpH0aacK"
      },
      "source": [
        "### Download external data (other)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ThxrLksgaM0o",
        "outputId": "2c603e0e-d599-47a4-d7ec-018652cce546"
      },
      "source": [
        "!wget https://people.eecs.berkeley.edu/~hendrycks/imagenet-a.tar\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-11-27 01:37:07--  https://people.eecs.berkeley.edu/~hendrycks/imagenet-a.tar\n",
            "Resolving people.eecs.berkeley.edu (people.eecs.berkeley.edu)... 128.32.189.73\n",
            "Connecting to people.eecs.berkeley.edu (people.eecs.berkeley.edu)|128.32.189.73|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 687552512 (656M) [application/x-tar]\n",
            "Saving to: ‘imagenet-a.tar’\n",
            "\n",
            "imagenet-a.tar      100%[===================>] 655.70M  40.7MB/s    in 17s     \n",
            "\n",
            "2020-11-27 01:37:24 (39.3 MB/s) - ‘imagenet-a.tar’ saved [687552512/687552512]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m0Q8k5UDagmB"
      },
      "source": [
        "### Download the challenge dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XFBKSMC1bzyG",
        "outputId": "41cd669b-e892-4605-8ef9-7418d58483b4"
      },
      "source": [
        "import gdown\n",
        "\n",
        "!gdown https://drive.google.com/u/0/uc?id=1NfaFbUQ9HUnzo-Ah5-jZoGBad9ajgMWQ&export=download\n",
        "!gdown https://drive.google.com/u/0/uc?id=16iIBC5IZc6l-LkzLwP6h3sXnuQckLo1E&export=download\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/u/0/uc?id=1NfaFbUQ9HUnzo-Ah5-jZoGBad9ajgMWQ\n",
            "To: /content/test_set_A_full.zip\n",
            "1.65GB [00:16, 98.4MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/u/0/uc?id=16iIBC5IZc6l-LkzLwP6h3sXnuQckLo1E\n",
            "To: /content/ai4vn_2020.zip\n",
            "323MB [00:04, 70.3MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9nc6b21sbhdg"
      },
      "source": [
        "!unzip -qq ai4vn_2020.zip\n",
        "\n",
        "!unzip -qq test_set_A_full.zip\n",
        "\n",
        "!mkdir test_data\n",
        "!mv test_set_A_full/ test_data/\n",
        "\n",
        "!tar -xvf imagenet-a.tar\n",
        "\n",
        "!mv imagenet-a/ 0/\n",
        "!mv 0/ ai4vn_2020/sample_data/\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KGwgqy78amxR"
      },
      "source": [
        "### Clone baseline source code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BOd22nGpbi53",
        "outputId": "e4b05737-d47e-4a75-f043-eb67731b6c08"
      },
      "source": [
        "\n",
        "!git clone https://github.com/hcmcaic/ai4vn-hackathon-2020.git\n",
        "%cd ai4vn-hackathon-2020/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'ai4vn-hackathon-2020'...\n",
            "remote: Enumerating objects: 9, done.\u001b[K\n",
            "remote: Counting objects: 100% (9/9), done.\u001b[K\n",
            "remote: Compressing objects: 100% (6/6), done.\u001b[K\n",
            "remote: Total 23 (delta 3), reused 8 (delta 3), pack-reused 14\u001b[K\n",
            "Unpacking objects: 100% (23/23), done.\n",
            "/content/ai4vn-hackathon-2020\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u04Rf7GTZ7bS"
      },
      "source": [
        "## Convert NoisyStudent EffecientNetB7 to a usable Keras model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NTh_MBTeWK07",
        "outputId": "dd9fdf1c-eb3a-4167-beb9-249a4aef985e"
      },
      "source": [
        "!wget https://storage.googleapis.com/cloud-tpu-checkpoints/efficientnet/noisystudent/noisy_student_efficientnet-b7.tar.gz\n",
        "!wget https://raw.githubusercontent.com/tensorflow/tensorflow/master/tensorflow/python/keras/applications/efficientnet_weight_update_util.py\n",
        "!tar -xf noisy_student_efficientnet-b7.tar.gz\n",
        "!python efficientnet_weight_update_util.py --model b7 --notop --ckpt \\\n",
        "        noisy-student-efficientnet-b7/model.ckpt --o efficientnetb7_notop.h5"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-11-27 01:38:45--  https://storage.googleapis.com/cloud-tpu-checkpoints/efficientnet/noisystudent/noisy_student_efficientnet-b7.tar.gz\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 172.217.204.128, 172.217.203.128, 74.125.139.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|172.217.204.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 491946084 (469M) [application/gzip]\n",
            "Saving to: ‘noisy_student_efficientnet-b7.tar.gz’\n",
            "\n",
            "noisy_student_effic 100%[===================>] 469.16M  97.3MB/s    in 5.1s    \n",
            "\n",
            "2020-11-27 01:38:51 (92.8 MB/s) - ‘noisy_student_efficientnet-b7.tar.gz’ saved [491946084/491946084]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jWt2OtHwaqX0"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import tensorflow as tf\n",
        "\n",
        "from dataloader import image_dataset_from_directory"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HPcEr7Y5Zxjr"
      },
      "source": [
        "# Data Loader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bHdiXPMTazPS",
        "outputId": "6dd21737-5184-455c-c199-f0d9279d238f"
      },
      "source": [
        "path_to_data = '/content/ai4vn_2020/sample_data'\n",
        "\n",
        "\n",
        "BATCH_SIZE = 10\n",
        "IMG_SIZE = (600, 600)\n",
        "\n",
        "NUM_CLASS = 8\n",
        "\n",
        "train_dataset, train_dataset_filenames = image_dataset_from_directory(path_to_data,\n",
        "                                             validation_split=0.2,\n",
        "                                             subset=\"training\",\n",
        "                                             shuffle=True,\n",
        "                                             seed=505,\n",
        "                                             batch_size=BATCH_SIZE,\n",
        "                                             image_size=IMG_SIZE)\n",
        "\n",
        "class_names =  train_dataset.class_names"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 11000 files belonging to 8 classes.\n",
            "Using 8800 files for training.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mOLV0o7na0Dv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a225b0a9-f4c9-4c22-c761-544127c66bc3"
      },
      "source": [
        "validation_dataset, validation_dataset_filenames = image_dataset_from_directory(path_to_data,\n",
        "                                                  validation_split=0.2,\n",
        "                                                  subset=\"validation\",\n",
        "                                                  shuffle=True,\n",
        "                                                  seed=505,\n",
        "                                                  batch_size=BATCH_SIZE,\n",
        "                                                  image_size=IMG_SIZE)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 11000 files belonging to 8 classes.\n",
            "Using 2200 files for validation.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eOSAj-lha2zb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "026d4038-dafe-40cd-8f44-6551f7ba4c40"
      },
      "source": [
        "test_dataset, test_dataset_filenames = image_dataset_from_directory('/content/test_data/',\n",
        "                                                  shuffle=False,\n",
        "                                                  batch_size=BATCH_SIZE,\n",
        "                                                  image_size=IMG_SIZE)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 19999 files belonging to 1 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eb4uKHzwa3ie"
      },
      "source": [
        "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
        "\n",
        "train_dataset = train_dataset.prefetch(buffer_size=AUTOTUNE)\n",
        "validation_dataset = validation_dataset.prefetch(buffer_size=AUTOTUNE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vE5kHKPKa4cJ"
      },
      "source": [
        "data_augmentation = tf.keras.Sequential([\n",
        "  # tf.keras.layers.experimental.preprocessing.Rescaling(1./255),\n",
        "  tf.keras.layers.experimental.preprocessing.RandomFlip('horizontal'),\n",
        "  tf.keras.layers.experimental.preprocessing.RandomRotation(0.05),\n",
        "  tf.keras.layers.experimental.preprocessing.RandomTranslation(height_factor=0.1, width_factor=0.1),\n",
        "  tf.keras.layers.experimental.preprocessing.RandomContrast(factor=0.1),\n",
        "  \n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0mBX3HIxZm1s"
      },
      "source": [
        "# Fine-tune model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q8kFBm5Ba5Vx"
      },
      "source": [
        "from tensorflow.keras.layers.experimental import preprocessing\n",
        "from tensorflow.keras.applications import EfficientNetB7\n",
        "\n",
        "\n",
        "def build_model(num_classes):\n",
        "    IMG_SIZE = 600\n",
        "    inputs = tf.keras.layers.Input(shape=(IMG_SIZE, IMG_SIZE, 3))\n",
        "    x = data_augmentation(inputs)\n",
        "    model = EfficientNetB7(include_top=False, input_tensor=x, weights=\"efficientnetb7_notop.h5\")\n",
        "\n",
        "    # Freeze the pretrained weights\n",
        "    model.trainable = False\n",
        "\n",
        "    # Rebuild top\n",
        "    x = tf.keras.layers.GlobalAveragePooling2D(name=\"avg_pool\")(model.output)\n",
        "    x = tf.keras.layers.BatchNormalization()(x)\n",
        "\n",
        "    top_dropout_rate = 0.2\n",
        "    x = tf.keras.layers.Dropout(top_dropout_rate, name=\"top_dropout\")(x)\n",
        "    outputs = tf.keras.layers.Dense(num_classes, activation=\"softmax\", name=\"pred\")(x)\n",
        "\n",
        "    # Compile\n",
        "    model = tf.keras.Model(inputs, outputs, name=\"EfficientNet\")\n",
        "    optimizer = tf.keras.optimizers.Adam(learning_rate=1e-2)\n",
        "    model.compile(\n",
        "        optimizer=optimizer, loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"]\n",
        "    )\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FvfLTIwKZgAS"
      },
      "source": [
        "### Freeze model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-nTcBy0Ta6xO",
        "outputId": "b742872c-0284-48c1-cdb8-8035a8c436f1"
      },
      "source": [
        "class_weights = {\n",
        "    0: 1/14,\n",
        "    1: 1.,\n",
        "    2: 1.,\n",
        "    3: 1.,\n",
        "    4: 1.,\n",
        "    5: 1.,\n",
        "    6: 1.,\n",
        "    7: 1.\n",
        "}\n",
        "\n",
        "model = build_model(num_classes=8)\n",
        "\n",
        "epochs = 25  # @param {type: \"slider\", min:8, max:80}\n",
        "hist = model.fit(train_dataset, epochs=epochs, validation_data=validation_dataset,\n",
        "                 class_weight=class_weights)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/25\n",
            "880/880 [==============================] - 659s 749ms/step - loss: 0.8362 - accuracy: 0.8540 - val_loss: 1.3525 - val_accuracy: 0.9414\n",
            "Epoch 2/25\n",
            "880/880 [==============================] - 655s 744ms/step - loss: 0.7672 - accuracy: 0.8920 - val_loss: 2.4286 - val_accuracy: 0.9145\n",
            "Epoch 3/25\n",
            "  1/880 [..............................] - ETA: 0s - loss: 0.2296 - accuracy: 0.9000"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "itvoKds0ZZ3q"
      },
      "source": [
        "### Unfreeze model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y_Uar1BObTLD"
      },
      "source": [
        "def unfreeze_model(model):\n",
        "    # We unfreeze the top 20 layers while leaving BatchNorm layers frozen\n",
        "    for layer in model.layers[-20:]:\n",
        "        if not isinstance(layer, tf.keras.layers.BatchNormalization):\n",
        "            layer.trainable = True\n",
        "\n",
        "    optimizer = tf.keras.optimizers.Adam(learning_rate=1e-4)\n",
        "    model.compile(\n",
        "        optimizer=optimizer, loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"]\n",
        "    )\n",
        "\n",
        "\n",
        "unfreeze_model(model)\n",
        "\n",
        "earlyStopping = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=5, verbose=0, mode='max')\n",
        "mcp_save = tf.keras.callbacks.ModelCheckpoint('best_model.hdf5', save_best_only=True, monitor='val_accuracy', mode='max')\n",
        "reduce_lr_loss = tf.keras.callbacks.ReduceLROnPlateau(monitor='loss', factor=0.1, patience=3, verbose=1, epsilon=1e-4, mode='min')\n",
        "\n",
        "epochs = 25  # @param {type: \"slider\", min:8, max:50}\n",
        "hist = model.fit(train_dataset, epochs=epochs, validation_data=validation_dataset,\n",
        "                  class_weight=class_weights,\n",
        "                  callbacks=[earlyStopping, mcp_save, reduce_lr_loss])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "39yH4yWVZieF"
      },
      "source": [
        "# Prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ds5VmejVW8y3"
      },
      "source": [
        "model = tf.keras.models.load_model('best_model.hdf5')\n",
        "\n",
        "\n",
        "predictions = model.predict(test_dataset)\n",
        "\n",
        "predicted_class = np.argmax(predictions, axis=-1)\n",
        "\n",
        "\n",
        "print('Predictions:\\n', predicted_class)\n",
        "# predicted_class[np.max(predictions, axis=-1) < 0.7] = 0\n",
        "\n",
        "with open('/content/submission.txt', 'w') as submission_file:\n",
        "  for filename, predicted in zip(test_dataset_filenames, predicted_class):\n",
        "    submission_file.write('{}\\t{}\\n'.format(filename.split('/')[-1], class_names[predicted]))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}